{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh9GaNvkumzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install plaidml-keras plaidbench"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UteAd73ZuvsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!plaidml-setup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rK-ddHwt-p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU Acceleration\n",
        "import plaidml.keras\n",
        "plaidml.keras.install_backend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZAakJPK-QPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standard import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmZ_AXvF-M4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# important features function\n",
        "def most_informative_feature(vectorizer, classifier, n=10):\n",
        "    class_labels = classifier.classes_\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
        "    class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
        "    print(\"Important FAKE news features\")\n",
        "    for coef, feat in class1:\n",
        "        print(class_labels[0], feat)\n",
        "    print()\n",
        "    print(\"Important REAL news features\")\n",
        "    for coef, feat in reversed(class2):  # reversed order\n",
        "        print(class_labels[1], feat)\n",
        "\n",
        "\n",
        "# scorer function\n",
        "def scorer(confusion_m):\n",
        "    tn, fp, fn, tp = confusion_m.ravel()\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = (2 * precision * recall) / (precision + recall)\n",
        "    print(\"Precision is: %0.3f\" % precision)\n",
        "    print(\"Recall is: %0.3f\" % recall)\n",
        "    print(\"F-1 Score is: %0.3f\" % f1_score)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-uBAsE7tuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data\n",
        "df = pd.read_csv('fake_or_real_news.csv')\n",
        "df = df.set_index('Unnamed: 0')\n",
        "y = df.label\n",
        "df = df.drop('label', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.3, random_state=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdRTVbFKcGph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 3000\n",
        "vocab_size = 80000\n",
        "num_classes = 2\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train.to_numpy())\n",
        "X_train = tokenizer.texts_to_sequences(X_train.to_numpy())\n",
        "X_test = tokenizer.texts_to_sequences(X_test.to_numpy())\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen, padding='post')\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train.factorize()[0], num_classes)\n",
        "y_test = np_utils.to_categorical(y_test.factorize()[0], num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_2oD4Pjcbg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01lmGv5c4PA",
        "colab_type": "code",
        "outputId": "a6908e35-d60c-4773-8fe4-c74621707cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 3, input_length=maxlen))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(32, 8, padding='valid', activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(32, 8, padding='valid', activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs = 25\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "model.summary();"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 3000, 3)           240000    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 3000, 3)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 2993, 32)          800       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2993, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 2986, 32)          8224      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 251,266\n",
            "Trainable params: 251,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odEMeo68dM6S",
        "colab_type": "code",
        "outputId": "aa8b2b52-7da0-465a-ae3f-a9d3de5fa070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "early = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32, callbacks=early);"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4434 samples, validate on 1901 samples\n",
            "Epoch 1/25\n",
            "4434/4434 [==============================] - 65s 15ms/step - loss: 0.6873 - acc: 0.5388 - val_loss: 0.6727 - val_acc: 0.6723\n",
            "Epoch 2/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.5517 - acc: 0.7203 - val_loss: 0.4798 - val_acc: 0.8001\n",
            "Epoch 3/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.4160 - acc: 0.8119 - val_loss: 0.3874 - val_acc: 0.8301\n",
            "Epoch 4/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.2692 - acc: 0.8929 - val_loss: 0.3689 - val_acc: 0.8222\n",
            "Epoch 5/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.1931 - acc: 0.9281 - val_loss: 0.2521 - val_acc: 0.8937\n",
            "Epoch 6/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.1485 - acc: 0.9445 - val_loss: 0.2814 - val_acc: 0.8738\n",
            "Epoch 7/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.1117 - acc: 0.9610 - val_loss: 0.2357 - val_acc: 0.9032\n",
            "Epoch 8/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.0902 - acc: 0.9689 - val_loss: 0.2038 - val_acc: 0.9190\n",
            "Epoch 9/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.0713 - acc: 0.9732 - val_loss: 0.2144 - val_acc: 0.9106\n",
            "Epoch 10/25\n",
            "4434/4434 [==============================] - 48s 11ms/step - loss: 0.0603 - acc: 0.9799 - val_loss: 0.2327 - val_acc: 0.9069\n",
            "Epoch 11/25\n",
            "4434/4434 [==============================] - 47s 11ms/step - loss: 0.0482 - acc: 0.9842 - val_loss: 0.2866 - val_acc: 0.8890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlitA4KkVbQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad8522a6-b2dd-4e41-e41d-e6df64b05365"
      },
      "source": [
        "# Final evaluation of the model\n",
        "pred_nn = model.predict(X_test)\n",
        "nn_score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy of CNN:   %0.3f\" % nn_score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of CNN:   0.919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIJM72O_sMCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "86957cfa-7ee0-4753-ab6e-a4dd2c4106e8"
      },
      "source": [
        "cm_nn = metrics.confusion_matrix(y_test.argmax(axis=1), pred_nn.argmax(axis=1))\n",
        "scorer(cm_nn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision is: 0.884\n",
            "Recall is: 0.967\n",
            "F-1 Score is: 0.924\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}